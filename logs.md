# Logs

## Log systems

### Syslog

#### Syslog Message Facilities

0 - kernel messages
1 - user-level messages
2 - mail system
3 - system daemons
4 - security/authorization messages
5 - messages generated internally by syslogd

See [RFC 5424](https://datatracker.ietf.org/doc/html/rfc5424#section-6.2.1)

#### Syslog Message Severities

0 - Emergency: system is unusable
1 - Alert: action must be taken immediately
2 - Critical: critical conditions
3 - Error: error conditions
4 - Warning: warning conditions
5 - Notice: normal but significant condition
6 - Informational: informational messages
7 - Debug: debug-level messages

### Logstash

[Logstash](https://www.elastic.co/logstash) is an open source server-side data processing pipeline that ingests data from a multitude of sources, transforms it, and then sends it to your favorite "stash.".
It's written in JRuby.

**ELK** — Elastic Search, Logstash, Kibana.

### Filebeat

[Filebeat](https://www.elastic.co/beats/filebeat) is a lightweight shipper for forwarding and centralizing log data. 
Installed as an agent on your servers, Filebeat monitors the log files or locations that you specify, 
collects log events, and forwards them either to Elasticsearch or Logstash for indexing.

Filebeat is a part of ELK stack.

### Fluentd

[Fluentd](https://www.fluentd.org/) is an open source data collector for unified logging layer.
Fluentd allows you to unify data collection and consumption for a better use and understanding of data.

It's written in СRuby.

#### Advantages:

- Unified logging: Collects from various sources and normalizes them into a standard format.
- Flexibility and Extensibility: Plugin-based architecture and customizability.
- Scalability and Reliability: Handles high volumes of data with buffering and retry mechanisms.
- Data routing and delivery: Supports multiple output destinations and dynamic routing.
- Open source and community-driven: Free to use and with a large and active community.

#### Config

File `/etc/td-agent/td-agent.conf` or `/etc/fluent/fluentd.conf`. It has blocks:

- `source` — info about data source. We can have many `source` blocks in a config file;
- `match` — has info about where to pass received data;
- `include` — info about file types;
- `system` — has system settings.

Plugins are used to connect to desired data source. Standard Plugins: `http` (for receiving HTTP-messages), `forward` (for receiving TCP-packets).

```
# Receive events from port 24224 /tcp
<source>
  type forward
  port 24224 
</source>

# http://this.host:9880/myapp.access?json={"event":"data"}
<source>
  type http
  port 9880
</source>
```

Every event from the data source has attributes: 

- `tag` - helps to understand where to route messages
- `time` - define here time
- `record` - data in JSON format

Message example:

```
# Generated by http://this.host:9880/myapp.access?json={"event":"data"}
tag: myapp.access
time: (current time)
record: {"event":"data"}
```

#### Match section

Describe features to select desired events. Standard output plugins: `file` and `forward`.

```
# Get events from port 24224
<source>
  type forward
  port 24224
</source>

# http://this.host:9880/myapp.access?json={"event":"data"}
<source>
  type http
  port 9880
</source>

# Take events with a tag "myapp.access" 
# and save them to a file /var/log/fluent/access.%Y-%m-%d
<match myapp.access>
  type file
  path /var/log/fluent/access
</match>
```
It means that all events marked with tags `myapp` and `access` we need to save to `/var/log/fluent/access`.
Events with any additional tag won't be sent to this file.

Match syntax:

- `<match a.*>` - selects `a.b` tag, but not `a.b.c`
- `<match **>` - selects any tag: `a` и `a.b`, `a.b.c`
- `<match {a, b}>` - selects at least one of defined tags: `a`, `b`, but not `c`
- `<match {a, b}. c.*>`, `<match {a.*, b}.c>*` - we can mix `{}` with `*`, `**`
- `<match a b>` - selects `a` and `b` at once
- `<match a.** b.*>` - selects tags `a`, `a.b` and `a.b.c` (left part) and `b.d` (right часть).

Important: Positon of `match` tags important in the config file. In the beginning we need to place concrete rules and after that only general rules. 

Correct example. General rules are at the bottom:

```
<match myapp.access>
  type file
  path /var/log/fluent/access
</match>

<match **>
  type blackhole_plugin
</match>
```

### Logs example

- To display boot and other kernel messages: `tail -f /var/log/messages`
- To view users and their activities: `tail -f /var/log/messages`

## Log Rotate

`logrotate` is a log managing command-line tool in Linux. 

The administrators write the rules and policies for handling different log files into configuration files. 
Through the configuration file, logrotate will execute the appropriate function to manage the matching log files.

Configs: `/etc/logrotate.conf`, `/etc/logrotate.d/*`

```bash
logrotate --help
```

Example of config file `/etc/logrotate.d/bootlog`:

```
/var/log/boot.log
{
    missingok
    daily
    copytruncate
    rotate 7
    notifempty
}
```

- `missingok` - If the log file is missing, go on to the next one without issuing an error message. 
- `daily` - Log files are rotated every day.
- `copytruncate` - Truncate the original log file in place after creating a copy, instead of moving the old log file and optionally creating a new one.
- `rotate 7` - Log files are rotated 7 times before being removed or mailed to the address specified in a mail directive.
- `notifempty` - Do not rotate the log if it is empty

See another [options](https://linux.die.net/man/8/logrotate)

## Links

- The Syslog Protocol [RFC 5424](https://datatracker.ietf.org/doc/html/rfc5424)
